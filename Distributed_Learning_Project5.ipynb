{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rPFlmzQnEloZ"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheS1n233/Distributed-Learning-Project5/blob/main/Distributed_Learning_Project5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install torch and torchvi"
      ],
      "metadata": {
        "id": "rPFlmzQnEloZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaveP5eCDkCO",
        "outputId": "8a987e42-5b19-4eb9-e3dd-3ce00f33ad2a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dataset CIFAR-100"
      ],
      "metadata": {
        "id": "LqSl_5NUFTDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 下载CIFAR-100数据集\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 训练集和验证集拆分\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# 创建验证集数据加载器\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 创建数据加载器\n",
        "\n",
        "def split_dataset(dataset, num_workers):\n",
        "    \"\"\"将数据集拆分为 num_workers 份\"\"\"\n",
        "    worker_datasets = torch.utils.data.random_split(\n",
        "        dataset, [len(dataset) // num_workers] * num_workers\n",
        "    )\n",
        "    return worker_datasets\n",
        "\n",
        "# Number of workers\n",
        "K = 4  # 假设有 4 个工作节点\n",
        "Bloc = 64  # 本地批量大小\n",
        "worker_datasets = split_dataset(train_dataset, K)\n",
        "worker_loaders = [\n",
        "    torch.utils.data.DataLoader(ds, batch_size=Bloc, shuffle=True) for ds in worker_datasets\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "9oP1XDeqExVw",
        "outputId": "13a638e3-269d-4b9f-9f67-e361c914de7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5ca02046c4bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 创建验证集数据加载器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centralized baseline"
      ],
      "metadata": {
        "id": "KpPjPiOTFatY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# define LeNet-5 model\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 初始化全局模型\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "global_model = LeNet5().to(device)\n",
        "\n",
        "# 每个工作节点初始化本地模型\n",
        "worker_models = [LeNet5().to(device) for _ in range(K)]\n",
        "for model in worker_models:\n",
        "    model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "# 本地更新函数\n",
        "def local_update(model, dataloader, criterion, optimizer, local_steps):\n",
        "    \"\"\"执行本地更新\"\"\"\n",
        "    model.train()\n",
        "    for _ in range(local_steps):\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model.state_dict()\n",
        "\n",
        "# 模型同步函数\n",
        "def average_parameters(global_model, local_states):\n",
        "    \"\"\"平均化所有工作节点的模型参数\"\"\"\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.stack(\n",
        "            [local_state[key] for local_state in local_states], dim=0\n",
        "        ).mean(dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# 定义损失函数和训练设置\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "H = 4  # 本地更新步数\n",
        "num_rounds = 10  # 全局同步轮数\n",
        "\n",
        "for round_idx in range(num_rounds):\n",
        "    print(f\"Round {round_idx + 1}/{num_rounds}\")\n",
        "\n",
        "    # 本地更新\n",
        "    local_states = []\n",
        "    for worker_id, (model, loader) in enumerate(zip(worker_models, worker_loaders)):\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "        local_state = local_update(model, loader, criterion, optimizer, H)\n",
        "        local_states.append(local_state)\n",
        "\n",
        "    # 模型同步\n",
        "    average_parameters(global_model, local_states)\n",
        "\n",
        "    # 同步后更新所有工作节点\n",
        "    for model in worker_models:\n",
        "        model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "# 测试全局模型\n",
        "correct, total = 0, 0\n",
        "global_model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in torch.utils.data.DataLoader(test_dataset, batch_size=Bloc, shuffle=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = global_model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"Global Model Test Accuracy: {100. * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6FFqW7ZFkWQ",
        "outputId": "b94ad1c8-3048-4ae1-ec7a-88d6f11f7ef4",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Epoch 1/5 completed.\n",
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Epoch 2/5 completed.\n",
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Epoch 3/5 completed.\n",
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Epoch 4/5 completed.\n",
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Epoch 5/5 completed.\n",
            "Test Accuracy: 1.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPPYaRako9Zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}