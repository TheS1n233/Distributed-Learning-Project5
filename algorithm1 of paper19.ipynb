{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rPFlmzQnEloZ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install torch and torchvision"
      ],
      "metadata": {
        "id": "rPFlmzQnEloZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaveP5eCDkCO",
        "outputId": "048b8f78-7b42-4390-a492-c69fc8ff8648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dataset CIFAR-100"
      ],
      "metadata": {
        "id": "LqSl_5NUFTDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# install CIFAR-100\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create a data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oP1XDeqExVw",
        "outputId": "15e22ddb-1ec1-4e87-a48e-4d37a6939676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 47.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Train dataset size: 50000\n",
            "Test dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centralized baseline"
      ],
      "metadata": {
        "id": "KpPjPiOTFatY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "batch_size = 64  # Batch size for training\n",
        "\n",
        "# Define the LeNet-5 model\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # Input: 3 channels (RGB), Output: 6 channels, Kernel size: 5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # Input: 6 channels, Output: 16 channels, Kernel size: 5\n",
        "        # Define the fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Flattened input size: 16 * 5 * 5\n",
        "        self.fc2 = nn.Linear(120, 84)  # 120 input units, 84 output units\n",
        "        self.fc3 = nn.Linear(84, 100)  # 84 input units, 100 output units (final classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # Apply ReLU activation on conv1 output\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling layer with 2x2 kernel\n",
        "        x = F.relu(self.conv2(x))  # Apply ReLU activation on conv2 output\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling layer with 2x2 kernel\n",
        "        x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation on fc1 output\n",
        "        x = F.relu(self.fc2(x))  # Apply ReLU activation on fc2 output\n",
        "        x = self.fc3(x)  # Final output layer (no activation here, raw scores)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Device configuration (GPU if available, else CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Local SGD Simulation function\n",
        "def local_sgd_simulation(model, train_loader, num_workers=4, local_steps=5, epochs=2):\n",
        "    # Move the model to the configured device\n",
        "    model_global = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        # Split the dataset into partitions for each worker\n",
        "        partition_size = len(train_loader.dataset) // num_workers\n",
        "        data_partitions = torch.utils.data.random_split(train_loader.dataset, [partition_size] * num_workers)\n",
        "\n",
        "        for worker_id, partition in enumerate(data_partitions):\n",
        "            print(f\"Worker {worker_id + 1}/{num_workers} processing...\")\n",
        "\n",
        "            # Create a local model for each worker, initialized with global model parameters\n",
        "            model_local = LeNet5().to(device)\n",
        "            model_local.load_state_dict(model_global.state_dict())  # Load the global model into the local model\n",
        "            optimizer = optim.SGD(model_local.parameters(), lr=0.01, momentum=0.9)  # Optimizer setup (SGD)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Learning rate scheduler\n",
        "\n",
        "            # Create data loader for the local partition\n",
        "            local_loader = torch.utils.data.DataLoader(partition, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
        "            model_local.train()  # Set the model to training mode\n",
        "\n",
        "            # Training loop for each worker\n",
        "            for _ in range(local_steps):\n",
        "                for inputs, labels in local_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = model_local(inputs)  # Get the model output\n",
        "                    loss = criterion(outputs, labels)  # Calculate the loss\n",
        "\n",
        "                    # Backward pass\n",
        "                    loss.backward()  # Compute gradients\n",
        "                    optimizer.step()  # Update model parameters\n",
        "\n",
        "                    epoch_loss += loss.item()  # Accumulate loss for this epoch\n",
        "\n",
        "                scheduler.step()  # Step the learning rate scheduler\n",
        "\n",
        "            # Synchronize local model weights with the global model (average weights)\n",
        "            with torch.no_grad():\n",
        "                for param_global, param_local in zip(model_global.parameters(), model_local.parameters()):\n",
        "                    param_global.data += (param_local.data - param_global.data) / num_workers\n",
        "\n",
        "\n",
        "        print('Loss/train', loss.item(), epoch)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n",
        "\n",
        "    return model_global  # Return the globally trained model\n",
        "\n",
        "\n",
        "# Training and testing\n",
        "model = LeNet5()  # Initialize the model\n",
        "trained_model = local_sgd_simulation(model, train_loader, 4, 3, 2)  # Train the model using local SGD simulation\n",
        "\n",
        "# Testing the trained model\n",
        "trained_model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "# Evaluate on test set\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = trained_model(inputs)  # Get predictions from the model\n",
        "        _, predicted = outputs.max(1)  # Get the predicted class index\n",
        "        all_labels.extend(labels.cpu().numpy())  # Collect true labels\n",
        "        all_preds.extend(predicted.cpu().numpy())  # Collect predicted labels\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "# Print test accuracy\n",
        "print(f\"Test Accuracy: {100. * correct / total:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6FFqW7ZFkWQ",
        "outputId": "d028608f-216e-42a3-ba30-ab5efcb781cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Worker 1/4 processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Loss/train 3.08390736579895 0\n",
            "Epoch 1/2 completed.\n",
            "Worker 1/4 processing...\n",
            "Worker 2/4 processing...\n",
            "Worker 3/4 processing...\n",
            "Worker 4/4 processing...\n",
            "Loss/train 3.319532871246338 1\n",
            "Epoch 2/2 completed.\n",
            "Test Accuracy: 18.62%\n"
          ]
        }
      ]
    }
  ]
}