{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheS1n233/Distributed-Learning-Project5/blob/experiments/Adaptive_J_LocalSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "KlHheqAGVUVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cc168c-46a0-4061-e984-529113618cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2T4ia3AsnT6"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "GPmLs0QzJQrO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import argparse\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "from torch.amp import GradScaler, autocast\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "1yoNOiteP6yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a12dc74-e862-4ed3-844b-4033462d92ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    raise RuntimeError(\"Google Drive not mounted correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-sEx0f8JJxK"
      },
      "source": [
        "# Costants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "Pmn-hp0TJNzX"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKER_LIST = [2]\n",
        "LOCAL_STEPS = [8]\n",
        "LR = 0.01\n",
        "WD = 0.001\n",
        "MOMENTUM = 0.9\n",
        "ALPHA = 1.0\n",
        "BETA = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNvH-6hEsuxY"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "da7YHCPoKnNK"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8oCJ42etBK_"
      },
      "source": [
        "## Function to get train, test and val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "OqrDqFDIJbRw"
      },
      "outputs": [],
      "source": [
        "def calulcate_mean_std(batch_size=100, verbose=True):\n",
        "    # Transform only for caluclate meaning of the dataset\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Load the CIFAR-100 training dataset\n",
        "    train_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Initialize sums for calculating mean and std\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "\n",
        "    for images, _ in train_loader:\n",
        "        # Compute mean and std for each channel\n",
        "        mean += images.mean(dim=[0, 2, 3])\n",
        "        std += images.std(dim=[0, 2, 3])\n",
        "\n",
        "    mean /= len(train_loader)\n",
        "    std /= len(train_loader)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Mean: \", mean)\n",
        "      print(\"Std: \", std)\n",
        "\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "sMQZou82OL3K"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, verbose=True):\n",
        "\n",
        "    print(\"Start loading data with batch_size\", batch_size)\n",
        "\n",
        "    mean, std = calulcate_mean_std()\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                            std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.CenterCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                            std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-100 dataset\n",
        "    start_time = time.time()\n",
        "    train_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"Dataset loading time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Split training and validation sets\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "      for i, (inputs, labels) in enumerate(train_loader):\n",
        "          print(f\"Batch {i}: inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "          if i == 10:\n",
        "              break\n",
        "      print(f\"Data loading for 10 batches completed.\")\n",
        "      print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "      print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "      print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "    print(\"Data load correctly...\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "5BLezwNAJfva"
      },
      "outputs": [],
      "source": [
        "class CheckpointSaver:\n",
        "\n",
        "  def __init__(self, path, additional_info, k, hyperparams, epochs):\n",
        "    self.timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    self.path = f\"{path}/K={k}_Comparison_{self.timestamp}\"\n",
        "    self.additional_info = additional_info\n",
        "    self.k = k\n",
        "    self.hyperparams = hyperparams\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def create_files(self):\n",
        "    os.makedirs(self.path, exist_ok=True)\n",
        "\n",
        "    self.metrics_files = {\n",
        "        'global_train_acc': os.path.join(self.path, f'adaptive_train_accuracy_{self.timestamp}_{str(self.additional_info)}.txt'),\n",
        "        'val_acc': os.path.join(self.path, f'adaptive_val_accuracy_{self.timestamp}_{str(self.additional_info)}.txt'),\n",
        "        'global_train_loss': os.path.join(self.path, f'adaptive_train_loss_{self.timestamp}_{str(self.additional_info)}.txt'),\n",
        "        'val_loss': os.path.join(self.path, f'adaptive_val_loss_{self.timestamp}_{str(self.additional_info)}.txt'),\n",
        "        'summary': os.path.join(self.path, f'adaptive_summary_{self.timestamp}_{str(self.additional_info)}.txt'),\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(self.path, f'adaptive_experiment_config_{self.timestamp}_{str(self.additional_info)}.txt'), 'w') as f:\n",
        "        f.write(f\"Experiment Configuration:\\n\")\n",
        "        f.write(f\"LocalSGD\\n\")\n",
        "        f.write(f\"K = {self.k};\\n\")\n",
        "        f.write(f\"Hyperparameters: {str(self.hyperparams)}\\n\")\n",
        "        f.write(f\"Number of epochs: {self.epochs}\\n\")\n",
        "        f.write(f\"Timestamp: {self.timestamp}\\n\")\n",
        "\n",
        "  def save_sumamry(self, epoch, global_train_accuracy, val_acc, global_train_loss, val_loss, stats):\n",
        "      try:\n",
        "          with open(self.metrics_files['summary'], 'a') as f:\n",
        "            f.write(f\"Epoch {epoch}\\n\")\n",
        "            f.write(f\"Train Loss: {global_train_loss:.4f}, Train Acc: {global_train_accuracy * 100:.2f}%\\n\")\n",
        "            f.write(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc * 100:.2f}%\\n\")\n",
        "            f.write(f\"Statistics: \\n{stats}\\n\")\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error saving metrics: {e}\")\n",
        "\n",
        "  def save_checkpoint(self, epoch, global_train_accuracy, val_acc, global_train_loss, val_loss):\n",
        "      try:\n",
        "          with open(self.metrics_files['global_train_acc'], 'a') as f:\n",
        "              f.write(f\"{epoch},{global_train_accuracy * 100:.2f}%\\n\")\n",
        "          with open(self.metrics_files['val_acc'], 'a') as f:\n",
        "              f.write(f\"{epoch},{val_acc * 100:.2f}%\\n\")\n",
        "          with open(self.metrics_files['global_train_loss'], 'a') as f:\n",
        "              f.write(f\"{epoch},{global_train_loss:.4f}\\n\")\n",
        "          with open(self.metrics_files['val_loss'], 'a') as f:\n",
        "              f.write(f\"{epoch},{val_loss:.4f}\\n\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error saving metrics: {e}\")\n",
        "\n",
        "  def end_sumamry(self, test_acc):\n",
        "      try:\n",
        "          with open(self.metrics_files['summary'], 'a') as f:\n",
        "            f.write(f\"test_acc {test_acc}\\n\")\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error saving metrics: {e}\")\n",
        "\n",
        "  def save_model_checkpoint(self, model, optimizer, epoch):\n",
        "      checkpoint_path = os.path.join(self.path, f'checkpoint_epoch_last_3.pth')\n",
        "      try:\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "          }, checkpoint_path)\n",
        "          print(\"Checkpoint saved correctly\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error saving model checkpoint: {e}\")\n",
        "\n",
        "  def load_model_checkpoint(self, checkpoint_path):\n",
        "      try:\n",
        "          checkpoint = torch.load(checkpoint_path)\n",
        "          start_epoch = checkpoint['epoch'] + 1\n",
        "          print(f\"Checkpoint loaded successfully. Resuming from epoch {start_epoch}\")\n",
        "          return checkpoint['model_state_dict'], checkpoint['optimizer_state_dict'], start_epoch\n",
        "      except Exception as e:\n",
        "          print(f\"Error loading model checkpoint: {e}\")\n",
        "          return 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeTracker:\n",
        "    def __init__(self):\n",
        "        self.computation_times = []\n",
        "        self.communication_times = []\n",
        "        self.epoch_avg_communication_time = []\n",
        "        self.total_computation = 0.0\n",
        "        self.total_communication = 0.0\n",
        "        self.epoch_comp_times = []\n",
        "        self.epoch_comm_times = []\n",
        "        self.epoch_ratio_times = []\n",
        "        self.epoch_local_step = []\n",
        "\n",
        "    def start_computation(self):\n",
        "        self.comp_start = time.time()\n",
        "\n",
        "    def end_computation(self):\n",
        "        comp_time = time.time() - self.comp_start\n",
        "        self.total_computation += comp_time\n",
        "        self.computation_times.append(comp_time)\n",
        "        return comp_time\n",
        "\n",
        "    def start_communication(self):\n",
        "        self.comm_start = time.time()\n",
        "\n",
        "    def end_communication(self):\n",
        "        comm_time = time.time() - self.comm_start\n",
        "        self.total_communication += comm_time\n",
        "        self.communication_times.append(comm_time)\n",
        "        return comm_time\n",
        "\n",
        "    def record_epoch(self,local_step):\n",
        "        \"\"\"Record times for the current epoch\"\"\"\n",
        "        self.epoch_avg_communication_time.append(np.mean(self.communication_times))\n",
        "        self.epoch_comp_times.append(self.total_computation)\n",
        "        self.epoch_comm_times.append(self.total_communication)\n",
        "        self.epoch_ratio_times.append(self.total_computation / (self.total_communication + 1e-10))\n",
        "        self.epoch_local_step.append(local_step)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"Return summary statistics\"\"\"\n",
        "        stats = {\n",
        "            'avg_computation_time': np.mean(self.computation_times),\n",
        "            'avg_communication_time': np.mean(self.communication_times),\n",
        "            'total_computation_time': self.total_computation,\n",
        "            'total_communication_time': self.total_communication,\n",
        "            'computation_to_communication_ratio': np.mean(self.epoch_ratio_times)\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    def str_statistics(self):\n",
        "        \"\"\"Return summary statistics\"\"\"\n",
        "        stats = f\"\"\"\n",
        "            'avg_computation_time': {np.mean(self.computation_times)},\n",
        "            'avg_communication_time': {np.mean(self.communication_times)},\n",
        "            'total_computation_time': {self.total_computation},\n",
        "            'total_communication_time': {self.total_communication},\n",
        "            'computation_to_communication_ratio': {np.mean(self.epoch_ratio_times)}\n",
        "        \"\"\"\n",
        "        return stats\n",
        "\n",
        "    def plot_times(self):\n",
        "        \"\"\"Plot computation and communication times\"\"\"\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # First graph: Plot cumulative times per epoch\n",
        "        plt.subplot(2, 1, 1)\n",
        "        epochs = range(1, len(self.epoch_comp_times) + 1)\n",
        "        plt.plot(epochs, self.epoch_ratio_times, label='ratio_times')\n",
        "\n",
        "        # Aggiungere linee verticali quando i valori in `epoch_local_step` cambiano\n",
        "        for i in range(1, len(self.epoch_local_step)):\n",
        "            if self.epoch_local_step[i] != self.epoch_local_step[i - 1]:\n",
        "                if self.epoch_local_step[i] > self.epoch_local_step[i - 1]:\n",
        "                    plt.axvline(x=i + 1, color='red', linestyle='--', alpha=0.7, label='Change' if i == 1 else \"\")\n",
        "                else:\n",
        "                    plt.axvline(x=i + 1, color='green', linestyle='--', alpha=0.7, label='Change' if i == 1 else \"\")\n",
        "\n",
        "\n",
        "        plt.title('Cumulative Times per Epoch - Ratio')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Total Time (s)')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(epochs, self.epoch_avg_communication_time, label='comm_time')\n",
        "\n",
        "        # Aggiungere linee verticali quando i valori in `epoch_local_step` cambiano\n",
        "        for i in range(1, len(self.epoch_local_step)):\n",
        "            if self.epoch_local_step[i] != self.epoch_local_step[i - 1]:\n",
        "                if self.epoch_local_step[i] > self.epoch_local_step[i - 1]:\n",
        "                    plt.axvline(x=i + 1, color='red', linestyle='--', alpha=0.7, label='Change' if i == 1 else \"\")\n",
        "                else:\n",
        "                    plt.axvline(x=i + 1, color='green', linestyle='--', alpha=0.7, label='Change' if i == 1 else \"\")\n",
        "\n",
        "\n",
        "        plt.title('Cumulative Times per Epoch - Comm time')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Total Time (s)')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "K9KMDGQ3xHkP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJaPDN4Qna1P"
      },
      "source": [
        "# Adaptive J LocalSGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SFiaXpZUnfDQ",
        "outputId": "19e0f52c-497b-4f76-ca8f-326fc63cb578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start loading data with batch_size 64\n",
            "Files already downloaded and verified\n",
            "Mean:  tensor([0.5071, 0.4865, 0.4409])\n",
            "Std:  tensor([0.2667, 0.2558, 0.2754])\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset loading time: 1.75 seconds\n",
            "Batch 0: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 1: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 2: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 3: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 4: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 5: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 6: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 7: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 8: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 9: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 10: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Data loading for 10 batches completed.\n",
            "Training dataset size: 40000\n",
            "Validation dataset size: 10000\n",
            "Test dataset size: 10000\n",
            "Data load correctly...\n",
            "In the beginning running LocalSGD with 2 workers and 8 initial local steps\n",
            "Starting training from scratch\n",
            "Adaptive_iterations_per_epoch: 39\n",
            "Statistics \n",
            "            'avg_computation_time': 0.4396498508942433,\n",
            "            'avg_communication_time': 0.0022917833083715192,\n",
            "            'total_computation_time': 17.14634418487549,\n",
            "            'total_communication_time': 0.08937954902648926,\n",
            "            'computation_to_communication_ratio': 191.83744326803566\n",
            "        \n",
            "Checkpoint saved correctly\n",
            "Epoch 1 / 10 | Val Loss: 4.0532, Val Acc: 7.53%\n",
            "Epoch 1, Worker 0: Current Learning Rate = 0.009755\n",
            "Epoch 1, Worker 1: Current Learning Rate = 0.009755\n",
            "Adaptive_iterations_per_epoch: 39\n",
            "Statistics \n",
            "            'avg_computation_time': 0.43596819730905384,\n",
            "            'avg_communication_time': 0.002291554059737768,\n",
            "            'total_computation_time': 34.0055193901062,\n",
            "            'total_communication_time': 0.1787412166595459,\n",
            "            'computation_to_communication_ratio': 191.04372975078755\n",
            "        \n",
            "Checkpoint saved correctly\n",
            "Epoch 2 / 10 | Val Loss: 3.7210, Val Acc: 12.88%\n",
            "Epoch 2, Worker 0: Current Learning Rate = 0.009045\n",
            "Epoch 2, Worker 1: Current Learning Rate = 0.009045\n",
            "Adaptive_iterations_per_epoch: 39\n",
            "Statistics \n",
            "            'avg_computation_time': 0.441991830483461,\n",
            "            'avg_communication_time': 0.002396946279411642,\n",
            "            'total_computation_time': 51.71304416656494,\n",
            "            'total_communication_time': 0.2804427146911621,\n",
            "            'computation_to_communication_ratio': 188.8284489937615\n",
            "        \n",
            "Checkpoint saved correctly\n",
            "Epoch 3 / 10 | Val Loss: 3.4926, Val Acc: 17.07%\n",
            "Epoch 3, Worker 0: Current Learning Rate = 0.007939\n",
            "Epoch 3, Worker 1: Current Learning Rate = 0.007939\n",
            "Adaptive_iterations_per_epoch: 39\n",
            "Statistics \n",
            "            'avg_computation_time': 0.45128068251487535,\n",
            "            'avg_communication_time': 0.0024802180436941292,\n",
            "            'total_computation_time': 70.39978647232056,\n",
            "            'total_communication_time': 0.3869140148162842,\n",
            "            'computation_to_communication_ratio': 187.10934167553333\n",
            "        \n",
            "Checkpoint saved correctly\n",
            "Epoch 4 / 10 | Val Loss: 3.3208, Val Acc: 19.60%\n",
            "Epoch 4, Worker 0: Current Learning Rate = 0.006545\n",
            "Epoch 4, Worker 1: Current Learning Rate = 0.006545\n",
            "Adaptive_iterations_per_epoch: 39\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-3a3f2b408569>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mini_local_steps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_steps_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"In the beginning running LocalSGD with {num_workers} workers and {ini_local_steps} initial local steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             train_losses, val_losses, train_accuracies, val_accuracies, test_acc, num_epochs, save_path = local_sgd_adaptive_steps(\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-3a3f2b408569>\u001b[0m in \u001b[0;36mlocal_sgd_adaptive_steps\u001b[0;34m(train_dataset, val_loader, test_loader, device, num_workers, ini_local_steps, num_epochs, batch_size, hyperparams)\u001b[0m\n\u001b[1;32m    100\u001b[0m                   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                       \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                           \u001b[0mworker_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def split_cifar100(dataset, num_workers):\n",
        "    indices = np.random.permutation(len(dataset))\n",
        "    splits = np.array_split(indices, num_workers)\n",
        "    return [torch.utils.data.Subset(dataset, split) for split in splits]\n",
        "\n",
        "\n",
        "def local_sgd_adaptive_steps(train_dataset, val_loader, test_loader, device, num_workers, ini_local_steps, num_epochs, batch_size, hyperparams):\n",
        "    dataset_size = len(train_dataset)\n",
        "    datasets = split_cifar100(train_dataset, num_workers)\n",
        "    workers = [\n",
        "        torch.utils.data.DataLoader(\n",
        "            datasets[i],\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        for i in range(num_workers)\n",
        "    ]\n",
        "\n",
        "    TOTAL_ITERATIONS = (num_epochs * (dataset_size // batch_size))\n",
        "    total_iterations = (num_epochs * (dataset_size // batch_size)) // (num_workers * ini_local_steps)\n",
        "    iterations_per_epoch = total_iterations // num_epochs\n",
        "    INI_iterations_per_epoch = iterations_per_epoch\n",
        "    remain_iterations = TOTAL_ITERATIONS\n",
        "\n",
        "    time_tracker = TimeTracker()\n",
        "\n",
        "    path = \"/content/drive/My Drive/Colab Notebooks/Traning_summary/\"\n",
        "    check_point_saver = CheckpointSaver(\n",
        "        path=path,\n",
        "        additional_info=f\"K={num_workers}\",\n",
        "        k=num_workers,\n",
        "        hyperparams=hyperparams,\n",
        "        epochs=num_epochs\n",
        "    )\n",
        "    global_model = LeNet5().to(device)\n",
        "    # Check for existing checkpoint\n",
        "    checkpoint_path = f\"{path}/K=2_Comparison_202kjhkjhggjhg/checkpoint_epoch_last_3.pth\"\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model_state_dict, optimizer_state_dict, start_epoch = check_point_saver.load_model_checkpoint(checkpoint_path)\n",
        "        global_model.load_state_dict(model_state_dict)\n",
        "\n",
        "        local_models = [copy.deepcopy(global_model).to(device) for _ in range(num_workers)]\n",
        "\n",
        "        local_optimizers = [\n",
        "            optim.SGD(\n",
        "                model.parameters(),\n",
        "                lr=hyperparams['lr'],\n",
        "                weight_decay=hyperparams['weight_decay'],\n",
        "                momentum=hyperparams['momentum'],\n",
        "            ) for model in local_models\n",
        "        ]\n",
        "\n",
        "        # Load the state dicts into each optimizer\n",
        "        for op in local_optimizers:\n",
        "            op.load_state_dict(optimizer_state_dict)\n",
        "\n",
        "        print(f\"Resumed training from iteration {start_epoch}\")\n",
        "    else:\n",
        "        print(\"Starting training from scratch\")\n",
        "\n",
        "        # Initialize local models and optimizers from scratch\n",
        "        local_models = [copy.deepcopy(global_model).to(device) for _ in range(num_workers)]\n",
        "        local_optimizers = [\n",
        "            optim.SGD(\n",
        "                model.parameters(),\n",
        "                lr=hyperparams['lr'],\n",
        "                weight_decay=hyperparams['weight_decay'],\n",
        "                momentum=hyperparams['momentum'],\n",
        "            ) for model in local_models\n",
        "        ]\n",
        "\n",
        "    check_point_saver.create_files()\n",
        "\n",
        "\n",
        "    schedulers = [CosineAnnealingLR(opt, T_max=num_epochs) for opt in local_optimizers]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    local_weights = [len(datasets[i].indices) / dataset_size for i in range(num_workers)]\n",
        "\n",
        "    val_losses, val_accuracies = [], []\n",
        "    train_losses, train_accuracies = [], []\n",
        "    local_steps = ini_local_steps\n",
        "    worker_iters = [iter(workers[i]) for i in range(num_workers)]\n",
        "\n",
        "    for loop_index in range(2):\n",
        "\n",
        "      for epoch in range(start_epoch + 1, num_epochs + 1):\n",
        "          # Update synchronization steps dynamically based on local steps\n",
        "          iterations_per_epoch = (dataset_size // batch_size) // (num_workers * local_steps)\n",
        "          print(f\"Adaptive_iterations_per_epoch: {iterations_per_epoch}\")\n",
        "          for iteration in range(iterations_per_epoch):\n",
        "              # Local training for local_steps\n",
        "\n",
        "              time_tracker.start_computation()\n",
        "\n",
        "              for worker_id in range(num_workers):\n",
        "                  local_models[worker_id].train()\n",
        "                  for _ in range(local_steps):\n",
        "                      try:\n",
        "                          inputs, labels = next(worker_iters[worker_id])\n",
        "                      except StopIteration:\n",
        "                          worker_iters[worker_id] = iter(workers[worker_id])\n",
        "                          inputs, labels = next(worker_iters[worker_id])\n",
        "\n",
        "                      inputs, labels = inputs.to(device), labels.to(device)\n",
        "                      local_optimizers[worker_id].zero_grad()\n",
        "                      outputs = local_models[worker_id](inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      loss.backward()\n",
        "                      local_optimizers[worker_id].step()\n",
        "\n",
        "              time_tracker.end_computation()\n",
        "              time_tracker.start_communication()\n",
        "\n",
        "\n",
        "              # Model averaging after local_steps\n",
        "              with torch.no_grad():\n",
        "                  global_state_dict = global_model.state_dict()\n",
        "                  for key in global_state_dict.keys():\n",
        "                      global_state_dict[key] = torch.sum(\n",
        "                          torch.stack([\n",
        "                              local_weights[i] * local_models[i].state_dict()[key]\n",
        "                              for i in range(num_workers)\n",
        "                          ]),\n",
        "                          dim=0\n",
        "                      )\n",
        "\n",
        "                  global_model.load_state_dict(global_state_dict)\n",
        "                  # Update local models with averaged weights\n",
        "                  for local_model in local_models:\n",
        "                      local_model.load_state_dict(global_state_dict)\n",
        "\n",
        "              time_tracker.end_communication()\n",
        "\n",
        "          global_model.eval()\n",
        "          global_train_loss, global_correct, global_total = 0.0, 0, 0\n",
        "          with torch.no_grad():\n",
        "                # Train on the global model after local updates\n",
        "                for inputs, labels in workers[0]:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = global_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    global_train_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    global_correct += predicted.eq(labels).sum().item()\n",
        "                    global_total += labels.size(0)\n",
        "          global_train_loss /= len(workers[0])\n",
        "          global_train_acc = global_correct / global_total\n",
        "          train_losses.append(global_train_loss)\n",
        "          train_accuracies.append(global_train_acc)\n",
        "\n",
        "          val_acc, val_loss = val_model(global_model, val_loader, criterion, device)\n",
        "          val_losses.append(val_loss)\n",
        "          val_accuracies.append(val_acc)\n",
        "          remain_iterations = remain_iterations - (iterations_per_epoch * num_workers * local_steps)\n",
        "\n",
        "          time_tracker.record_epoch(local_steps)\n",
        "          print(f\"Statistics\", time_tracker.str_statistics())\n",
        "\n",
        "          # adjustment of local steps\n",
        "          if epoch > 1 and len(val_losses) > 1:\n",
        "              # Adjust delta_min based on epoch range\n",
        "\n",
        "              delta_loss = (val_losses[-2] - val_loss) / val_losses[-2]\n",
        "              if epoch <= num_epochs * 0.2:\n",
        "                  delta_min = hyperparams['delta_min_initial']\n",
        "              elif epoch <= num_epochs * 0.8:\n",
        "                  delta_min = hyperparams['delta_min_mid']\n",
        "              else:\n",
        "                  delta_min = hyperparams['delta_min_final']\n",
        "\n",
        "              if 0 < delta_loss < delta_min:  # Slow convergence\n",
        "                  local_steps = min(local_steps * 2, hyperparams['max_local_steps'])\n",
        "                  print(f\"Delta loss: {delta_loss} | Epoch {epoch}: Increasing local steps000 to {local_steps}\")\n",
        "\n",
        "              if epoch > num_epochs * 0.3:\n",
        "                if delta_loss < 0 and abs(delta_loss) > hyperparams['delta_min_initial']:  # Significant oscillation\n",
        "                    local_steps = max(local_steps // 2, hyperparams['min_local_steps'])\n",
        "                    print(f\"Delta loss: {delta_loss} | Epoch {epoch}: Decreasing local steps222 due to significant oscillation to {local_steps}\")\n",
        "\n",
        "\n",
        "          # Log training and validation metrics\n",
        "\n",
        "          check_point_saver.save_checkpoint(epoch, global_train_acc, val_acc, global_train_loss, val_loss)\n",
        "          check_point_saver.save_sumamry(epoch, global_train_acc, val_acc, global_train_loss, val_loss, time_tracker.str_statistics())\n",
        "          check_point_saver.save_model_checkpoint(global_model, local_optimizers[0], epoch)\n",
        "\n",
        "          print(f\"Epoch {epoch} / {num_epochs} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc * 100:.2f}%\")\n",
        "\n",
        "          # Step schedulers after each epoch\n",
        "          for scheduler in schedulers:\n",
        "              scheduler.step()\n",
        "          for worker_id, optimizer in enumerate(local_optimizers):\n",
        "              current_lr = optimizer.param_groups[0]['lr']\n",
        "              print(f\"Epoch {epoch}, Worker {worker_id}: Current Learning Rate = {current_lr:.6f}\")\n",
        "      # Calculate how many iterations we still have, and keep training\n",
        "      if loop_index == 0:\n",
        "        remain_epochs = max(1, remain_iterations // (num_workers * ini_local_steps * INI_iterations_per_epoch))\n",
        "      num_epochs = remain_epochs\n",
        "      print(f\"Remain iterations:{remain_iterations}| Remain Epoch: {num_epochs}\")\n",
        "      local_steps = ini_local_steps\n",
        "      last_lr = 0.0001 #initial 2nd loop learning rate\n",
        "      for optimizer in local_optimizers:\n",
        "        for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = last_lr\n",
        "      new_schedulers = [\n",
        "        optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "        for optimizer in local_optimizers\n",
        "      ]\n",
        "      schedulers = new_schedulers\n",
        "    # Test the final model\n",
        "    test_acc = test_model(global_model, test_loader, device)\n",
        "\n",
        "    time_tracker.plot_times()\n",
        "    check_point_saver.end_sumamry(test_acc)\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies, test_acc, num_epochs, check_point_saver.path\n",
        "\n",
        "\n",
        "def val_model(global_model, val_loader, criterion, device):\n",
        "    global_model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = global_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = correct / total\n",
        "    return val_acc, val_loss\n",
        "\n",
        "def test_model(global_model, test_loader, device):\n",
        "    global_model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = global_model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "    return test_acc\n",
        "\n",
        "\n",
        "def plot_results(train_losses, val_losses, train_accuracies, val_accuracies, NUM_EPOCHS, num_epochs, save_path):\n",
        "    total_epochs = NUM_EPOCHS + num_epochs\n",
        "    x_vals = list(range(1, total_epochs + 1))\n",
        "    assert len(train_losses) == total_epochs, f\"Mismatch: train_losses={len(train_losses)} vs total_epochs={total_epochs}\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x_vals, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(x_vals, val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss over Epochs\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x_vals, train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(x_vals, val_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy over Epochs\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_path}/training_results.png\")\n",
        "    print(f\"Training results saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    num_epochs = NUM_EPOCHS\n",
        "    batch_size = BATCH_SIZE\n",
        "    num_workers_list = NUM_WORKER_LIST\n",
        "    local_steps_list = LOCAL_STEPS\n",
        "    hyperparams = {\n",
        "        'lr': LR,\n",
        "        'weight_decay': WD,\n",
        "        'momentum': MOMENTUM,\n",
        "        'delta_min_initial': 0.02,\n",
        "        'delta_min_mid': 0.005,\n",
        "        'delta_min_final': 0.002,\n",
        "        'max_local_steps': 64,\n",
        "        'min_local_steps': 4\n",
        "    }\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_dataset(batch_size)\n",
        "    train_dataset = train_loader.dataset\n",
        "\n",
        "    for num_workers in num_workers_list:\n",
        "        for ini_local_steps in local_steps_list:\n",
        "            print(f\"In the beginning running LocalSGD with {num_workers} workers and {ini_local_steps} initial local steps\")\n",
        "            train_losses, val_losses, train_accuracies, val_accuracies, test_acc, num_epochs, save_path = local_sgd_adaptive_steps(\n",
        "                train_dataset=train_dataset,\n",
        "                val_loader=val_loader,\n",
        "                test_loader=test_loader,\n",
        "                device=device,\n",
        "                num_workers=num_workers,\n",
        "                ini_local_steps=ini_local_steps,\n",
        "                num_epochs=num_epochs,\n",
        "                batch_size=batch_size,\n",
        "                hyperparams=hyperparams,\n",
        "            )\n",
        "\n",
        "\n",
        "            plot_results(train_losses, val_losses, train_accuracies, val_accuracies, NUM_EPOCHS, num_epochs, save_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yq14ax2G2tcx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bNvH-6hEsuxY"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}