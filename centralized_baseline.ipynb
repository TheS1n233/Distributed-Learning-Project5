{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheS1n233/Distributed-Learning-Project5/blob/experiments/centralized_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvmju5T5JiiO"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision matplotlib\n",
        "!pip install --upgrade torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI3dqA44JiiP"
      },
      "source": [
        "## Import of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD0gTWyoJiiQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torch.amp import GradScaler, autocast\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Mfws2lJiiQ"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    raise RuntimeError(\"Google Drive not mounted correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnPO_7g0JiiR"
      },
      "source": [
        "## Costants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsCbRpR6JiiR"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-s5YWl4JiiR"
      },
      "source": [
        "## Pre processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bujrWFPuo-L"
      },
      "outputs": [],
      "source": [
        "# Define the transform to only convert the images to tensors (without normalization yet)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the CIFAR-100 training dataset\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize sums for calculating mean and std\n",
        "mean = torch.zeros(3)\n",
        "std = torch.zeros(3)\n",
        "\n",
        "for images, _ in train_loader:\n",
        "    # Compute mean and std for each channel\n",
        "    mean += images.mean(dim=[0, 2, 3])  # Mean per channel (R, G, B)\n",
        "    std += images.std(dim=[0, 2, 3])  # Std per channel (R, G, B)\n",
        "\n",
        "mean /= len(train_loader)\n",
        "std /= len(train_loader)\n",
        "\n",
        "print(\"Mean: \", mean)\n",
        "print(\"Std: \", std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R2xi_lxJiiS"
      },
      "outputs": [],
      "source": [
        "# Custom Cutout\n",
        "\"\"\"class Cutout(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "        y1 = np.clip(y - self.size // 2, 0, h)\n",
        "        y2 = np.clip(y + self.size // 2, 0, h)\n",
        "        x1 = np.clip(x - self.size // 2, 0, w)\n",
        "        x2 = np.clip(x + self.size // 2, 0, w)\n",
        "        if len(img.shape) == 2:  # Handle grayscale images\n",
        "            img = img * mask\n",
        "        else:\n",
        "            img = img * mask[:, :, np.newaxis]\n",
        "\n",
        "        return Image.fromarray(np.uint8(img))\"\"\"\n",
        "\n",
        "\"\"\"# Mixup function\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0.0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.0\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\"\"\"\n",
        "\n",
        "# Data transformations with additional augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(24),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                         std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.CenterCrop(24),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                         std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "start_time = time.time()\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train\n",
        ")\n",
        "test_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test\n",
        ")\n",
        "print(f\"Dataset loading time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Split training and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Debugging: Check DataLoader outputs\n",
        "for i, (inputs, labels) in enumerate(train_loader):\n",
        "    print(f\"Batch {i}: inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    if i == 10:  # Test first 10 batches\n",
        "        break\n",
        "print(f\"Data loading for 10 batches completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otaf-0hUJiiS"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-ggfWQdJiiS"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # Layer convolutivi\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)  # 3 input channels, 64 output channels\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)  # 64 input channels, 64 output channels\n",
        "\n",
        "        # Layer fully connected\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)  # Dimensione calcolata per input 32x32 con due conv e max-pooling\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)  # Classificatore lineare per CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer convolutivi con ReLU e max-pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "\n",
        "        # Flatten per i layer fully connected\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Layer fully connected con ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Classificatore lineare\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # Softmax per probabilit√†\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjj2cgXtJiiT"
      },
      "source": [
        "## Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxChxZkGJiiT"
      },
      "outputs": [],
      "source": [
        "# Early Stopping Class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='/content/drive/MyDrive/Early2checkpoint.pt', verbose=False):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, optimizer=None):\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\")\n",
        "        checkpoint = {\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss_min': val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZXMzbb9JiiT"
      },
      "source": [
        "## Centralized baseline training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC1vt63oJiiT"
      },
      "outputs": [],
      "source": [
        "# Centralized baseline training function\n",
        "def train_model_with_hyperparams(train_loader, val_loader, test_loader, best_hyperparams, num_epochs, device, checkpoint_path, type_of_optimizer):\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    if type_of_optimizer == \"SDGM\":\n",
        "        if best_hyperparams.get('momentum', None) is None:\n",
        "            raise ValueError(\"Momentum is required for SGDM\")\n",
        "        if best_hyperparams.get('weight_decay', None) is None:\n",
        "            raise ValueError(\"Weight decay is required for SGDM\")\n",
        "        if best_hyperparams.get('lr', None) is None:\n",
        "            raise ValueError(\"Learning rate is required for SGDM\")\n",
        "\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=best_hyperparams['lr'],\n",
        "            momentum=best_hyperparams['momentum'],\n",
        "            weight_decay=best_hyperparams['weight_decay']\n",
        "        )\n",
        "\n",
        "    elif type_of_optimizer == \"AdamW\":\n",
        "        if best_hyperparams.get('lr', None) is None:\n",
        "            raise ValueError(\"Learning rate is required for AdamW\")\n",
        "        if best_hyperparams.get('weight_decay', None) is None:\n",
        "            raise ValueError(\"Weight decay is required for AdamW\")\n",
        "\n",
        "        optimizer = optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=best_hyperparams['lr'],\n",
        "            weight_decay=best_hyperparams['weight_decay']\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid optimizer type\")\n",
        "\n",
        "\n",
        "    print(f\"Train running whith {type_of_optimizer} optimizer.\")\n",
        "\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    early_stopping = EarlyStopping(patience=best_hyperparams.get('patience', 5), verbose=True)\n",
        "\n",
        "    # Checkpoint recovery\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Checkpoint found at {checkpoint_path}. Loading model state...\")\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {checkpoint_path}. Training a new model from scratch.\")\n",
        "        checkpoint = None\n",
        "\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss_total, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss_total += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss_total / len(train_loader)\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss_total, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "                with autocast(device_type=device.type):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss_total += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss_total / len(val_loader)\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "        early_stopping(val_loss, model)\n",
        "\n",
        "        # Save checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_accuracies': train_accuracies,\n",
        "            'val_accuracies': val_accuracies\n",
        "        }\n",
        "\n",
        "        torch.save(checkpoint, '/content/drive/MyDrive/CentralizedCheckpoint.pth')\n",
        "        print(f\"Checkpoint saved to Google Drive at epoch {epoch + 1}\")\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    # Load the best model\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/Early2checkpoint.pt')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Test loop\n",
        "    model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_acc = 100. * test_correct / test_total\n",
        "    print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmiych7HJiiU"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdyWGKLAJiiU"
      },
      "outputs": [],
      "source": [
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Use the best hyperparameters from random search\n",
        "\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/best_hyperparams_SDGM.json', 'r') as f:\n",
        "            best_hyperparams = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        best_hyperparams = {\n",
        "            'lr': 0.01,\n",
        "            'weight_decay': 0.005,\n",
        "            'momentum': 0.9,\n",
        "            'patience': 100\n",
        "        }\n",
        "\n",
        "    print(\"\\nUsing Best Hyperparameters from Random Search:\", best_hyperparams)\n",
        "\n",
        "    # Train with the best hyperparameters\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies, test_acc = train_model_with_hyperparams(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        test_loader=test_loader,\n",
        "        best_hyperparams=best_hyperparams,\n",
        "        num_epochs=150,\n",
        "        device=device,\n",
        "        checkpoint_path='/content/drive/MyDrive/checkpoint1.pth',\n",
        "        type_of_optimizer=\"SDGM\"\n",
        "    )\n",
        "\n",
        "    # Plot results\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # Save the plot before showing it\n",
        "    save_path = '/content/drive/My Drive/Colab Notebooks/Traning_summary/Traning2'\n",
        "    plt.savefig(save_path + 'training_results.png')\n",
        "    print(\"Training results saved to Google Drive as 'training_results.png'\")\n",
        "    plt.show()\n",
        "\n",
        "    # Save the summary\n",
        "    with open(save_path + 'training_summary.txt', 'w') as f:\n",
        "        f.write(f\"Final Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "        f.write(\"Training and Validation Results:\\n\")\n",
        "        f.write(f\"Train Losses: {train_losses}\\n\")\n",
        "        f.write(f\"Validation Losses: {val_losses}\\n\")\n",
        "        f.write(f\"Train Accuracies: {train_accuracies}\\n\")\n",
        "        f.write(f\"Validation Accuracies: {val_accuracies}\\n\")\n",
        "\n",
        "    print(\"Training summary saved to Google Drive as 'training_summary.txt'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m1_BYCKJiiU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path\n",
        "save_path = '/content/drive/My Drive/Colab Notebooks/Traning_summary/Traning1_ACC53.15%'\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(save_path + 'training_results.png')\n",
        "print(\"Training results saved to Google Drive as 'training_results.png'\")\n",
        "\n",
        "# Save the summary\n",
        "with open(save_path + 'training_summary.txt', 'w') as f:\n",
        "    f.write(f\"Final Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "    f.write(\"Training and Validation Results:\\n\")\n",
        "    f.write(f\"Train Losses: {train_losses}\\n\")\n",
        "    f.write(f\"Validation Losses: {val_losses}\\n\")\n",
        "    f.write(f\"Train Accuracies: {train_accuracies}\\n\")\n",
        "    f.write(f\"Validation Accuracies: {val_accuracies}\\n\")\n",
        "print(\"Training summary saved to Google Drive as 'training_summary.txt'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bI3dqA44JiiP",
        "lnPO_7g0JiiR",
        "U-s5YWl4JiiR",
        "Otaf-0hUJiiS",
        "zjj2cgXtJiiT"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}