{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rPFlmzQnEloZ"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheS1n233/Distributed-Learning-Project5/blob/test/Distributed_Learning_Project5_HYPERPARAMSFINDING_ANDREA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install torch and torchvi"
      ],
      "metadata": {
        "id": "rPFlmzQnEloZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TaveP5eCDkCO",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da312c54-af4a-4045-853a-b99949e2d8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib\n",
        "!pip install --upgrade torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dataset CIFAR-100"
      ],
      "metadata": {
        "id": "LqSl_5NUFTDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data preprocessing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Download CIFAR-100 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split training and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "9oP1XDeqExVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f91c617-0e39-4ce0-957b-518633f5f464"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:18<00:00, 9.19MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "# Data preprocessing\n",
        "class Cutout(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "        y1 = np.clip(y - self.size // 2, 0, h)\n",
        "        y2 = np.clip(y + self.size // 2, 0, h)\n",
        "        x1 = np.clip(x - self.size // 2, 0, w)\n",
        "        x2 = np.clip(x + self.size // 2, 0, w)\n",
        "        mask[y1: y2, x1: x2] = 0\n",
        "        img = img * mask[:, :, np.newaxis]\n",
        "\n",
        "        return Image.fromarray(np.uint8(img))\n",
        "\n",
        "# Data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    Cutout(size=8),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def load_cifar100():\n",
        "    \"\"\"Load and prepare CIFAR-100 dataset\"\"\"\n",
        "    train_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test\n",
        "    )\n",
        "\n",
        "    # Split training and validation sets\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # Layer convolutivi\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)  # 3 input channels, 64 output channels\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)  # 64 input channels, 64 output channels\n",
        "\n",
        "        # Layer fully connected\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)  # Dimensione calcolata per input 32x32 con due conv e max-pooling\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)  # Classificatore lineare per CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer convolutivi con ReLU e max-pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "\n",
        "        # Flatten per i layer fully connected\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Layer fully connected con ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Classificatore lineare\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # Softmax per probabilità\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def check_initial_loss(model, train_loader, device):\n",
        "    \"\"\"Step 1: Check initial loss at initialization\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs, labels = next(iter(train_loader))\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        expected_loss = math.log(100)\n",
        "        print(f\"Initial loss: {loss.item():.4f}\")\n",
        "        print(f\"Expected loss: {expected_loss:.4f}\")\n",
        "        return abs(loss.item() - expected_loss) < 1.0\n",
        "\n",
        "def overfit_small_sample(model, train_loader, device, max_iterations=1000):\n",
        "    \"\"\"Step 2: Overfit a small sample\"\"\"\n",
        "    # Get small sample (5 minibatches)\n",
        "    small_dataset = []\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        if i >= 5:\n",
        "            break\n",
        "        small_dataset.extend(list(zip(inputs, labels)))\n",
        "\n",
        "    small_loader = torch.utils.data.DataLoader(small_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    model.train()\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in small_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        accuracy = 100. * correct / total\n",
        "        avg_loss = total_loss / len(small_loader)\n",
        "\n",
        "        if iteration % 50 == 0:\n",
        "            print(f\"Iteration {iteration}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        if accuracy > 99:\n",
        "            print(\"Successfully overfit small sample!\")\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def find_initial_lr(model, train_loader, device, lrs=[1e-1, 1e-2, 1e-3, 1e-4]):\n",
        "    \"\"\"Step 3: Find LR that makes loss go down\"\"\"\n",
        "    best_lr = None\n",
        "    min_loss_decrease = float('inf')\n",
        "\n",
        "    for lr in lrs:\n",
        "        model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-5, momentum=0.9)\n",
        "        initial_loss = None\n",
        "        final_loss = None\n",
        "\n",
        "        print(f\"\\nTrying learning rate: {lr}\")\n",
        "\n",
        "        for iteration in range(100):\n",
        "            inputs, labels = next(iter(train_loader))\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "            if iteration == 0:\n",
        "                initial_loss = loss.item()\n",
        "            final_loss = loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iteration % 20 == 0:\n",
        "                print(f\"Iteration {iteration}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        loss_decrease = initial_loss - final_loss\n",
        "        print(f\"Loss decrease: {loss_decrease:.4f}\")\n",
        "\n",
        "        if loss_decrease > 0 and loss_decrease < min_loss_decrease:\n",
        "            min_loss_decrease = loss_decrease\n",
        "            best_lr = lr\n",
        "\n",
        "    return best_lr\n",
        "\n",
        "def coarse_grid_search(model, train_loader, val_loader, device, best_lr):\n",
        "    \"\"\"Step 4: Coarse grid search\"\"\"\n",
        "    lrs = [best_lr / 2, best_lr, best_lr * 2]\n",
        "    weight_decays = [0, 1e-5, 1e-4]\n",
        "    momentum_arr = [0.9, 0.95]\n",
        "    results = []\n",
        "\n",
        "    for lr in lrs:\n",
        "        for wd in weight_decays:\n",
        "            momentum = random.choice(momentum_arr)\n",
        "            print(f\"\\nTrying LR: {lr}, Weight Decay: {wd}\")\n",
        "            model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "            train_losses = []\n",
        "            val_accuracies = []\n",
        "\n",
        "            for epoch in range(5):\n",
        "                # Training\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = F.cross_entropy(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                # Validation\n",
        "                model.eval()\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                    for inputs, labels in val_loader:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        total += labels.size(0)\n",
        "                        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                train_losses.append(total_loss / len(train_loader))\n",
        "                val_accuracies.append(100. * correct / total)\n",
        "\n",
        "                print(f\"Epoch {epoch + 1}, Loss: {train_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%\")\n",
        "\n",
        "            results.append({\n",
        "                'lr': lr,\n",
        "                'weight_decay': wd,\n",
        "                'final_loss': train_losses[-1],\n",
        "                'final_val_acc': val_accuracies[-1],\n",
        "                'momentum': momentum\n",
        "            })\n",
        "\n",
        "    results.sort(key=lambda x: x['final_val_acc'], reverse=True)\n",
        "    return results[0]\n",
        "\n",
        "def train_model_with_early_stopping(model, optimizer, criterion, scheduler, train_loader, val_loader, num_epochs, device, patience=5):\n",
        "    \"\"\"Train model with early stopping\"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(100. * correct / total)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(100. * correct / total)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
        "              f\"Train Acc: {train_accuracies[-1]:.2f}%, \"\n",
        "              f\"Val Loss: {val_losses[-1]:.4f}, \"\n",
        "              f\"Val Acc: {val_accuracies[-1]:.2f}%\")\n",
        "\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
        "\n",
        "def main():\n",
        "    # Setup device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load CIFAR-100 data\n",
        "    train_loader, val_loader, test_loader = load_cifar100()\n",
        "\n",
        "    # Initialize model\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    # Step 1: Check initial loss\n",
        "    if check_initial_loss(model, train_loader, device):\n",
        "        print(\"Initial loss check passed.\")\n",
        "\n",
        "    # Step 2: Overfit small sample\n",
        "    if overfit_small_sample(model, train_loader, device):\n",
        "        print(\"Successfully overfit small sample.\")\n",
        "\n",
        "    # Step 3: Find learning rate\n",
        "    best_lr = find_initial_lr(model, train_loader, device)\n",
        "    print(f\"Best learning rate: {best_lr}\")\n",
        "\n",
        "    # Step 4: Coarse grid search for LR and weight decay\n",
        "    best_model_params = coarse_grid_search(model, train_loader, val_loader, device, best_lr)\n",
        "    print(f\"Best model parameters: {best_model_params}\")\n",
        "\n",
        "    for improvement in range(1, 3):\n",
        "      # Step 5: Refine grid search and train for longer\n",
        "      # Train with the best parameters found\n",
        "      best_lr = best_model_params['lr']\n",
        "      best_weight_decay = best_model_params['weight_decay']\n",
        "      model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "      optimizer = optim.SGD(model.parameters(), lr=best_lr, weight_decay=best_weight_decay, momentum=best_model_params['momentum'])\n",
        "      scheduler = CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "      # Train the model for 10-20 epochs\n",
        "      model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_early_stopping(\n",
        "          model, optimizer, F.cross_entropy, scheduler, train_loader, val_loader, num_epochs=20*improvement, device=device, patience=5\n",
        "      )\n",
        "\n",
        "      # Step 6: Look at learning curves\n",
        "      # Plot training and validation losses and accuracies\n",
        "      import matplotlib.pyplot as plt\n",
        "      epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "      plt.figure(figsize=(12, 5))\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "      plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
        "      plt.xlabel(\"Epochs\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend()\n",
        "\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
        "      plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\")\n",
        "      plt.xlabel(\"Epochs\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.legend()\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L6nHeatWRyn-",
        "outputId": "57cb2ca3-87a4-43df-fe86-d88f60cc4736"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Initial loss: 4.6055\n",
            "Expected loss: 4.6052\n",
            "Initial loss check passed.\n",
            "Iteration 0, Loss: 4.6025, Accuracy: 1.88%\n",
            "Iteration 50, Loss: 0.1454, Accuracy: 96.25%\n",
            "Successfully overfit small sample!\n",
            "Successfully overfit small sample.\n",
            "\n",
            "Trying learning rate: 0.1\n",
            "Iteration 0, Loss: 4.6025\n",
            "Iteration 20, Loss: 4.5855\n",
            "Iteration 40, Loss: 4.5921\n",
            "Iteration 60, Loss: 4.5818\n",
            "Iteration 80, Loss: 4.5955\n",
            "Loss decrease: 0.0349\n",
            "\n",
            "Trying learning rate: 0.01\n",
            "Iteration 0, Loss: 4.6024\n",
            "Iteration 20, Loss: 4.6051\n",
            "Iteration 40, Loss: 4.5996\n",
            "Iteration 60, Loss: 4.6097\n",
            "Iteration 80, Loss: 4.5982\n",
            "Loss decrease: 0.0021\n",
            "\n",
            "Trying learning rate: 0.001\n",
            "Iteration 0, Loss: 4.6148\n",
            "Iteration 20, Loss: 4.5986\n",
            "Iteration 40, Loss: 4.6062\n",
            "Iteration 60, Loss: 4.6011\n",
            "Iteration 80, Loss: 4.6008\n",
            "Loss decrease: 0.0118\n",
            "\n",
            "Trying learning rate: 0.0001\n",
            "Iteration 0, Loss: 4.5986\n",
            "Iteration 20, Loss: 4.6060\n",
            "Iteration 40, Loss: 4.6097\n",
            "Iteration 60, Loss: 4.6109\n",
            "Iteration 80, Loss: 4.6126\n",
            "Loss decrease: -0.0103\n",
            "Best learning rate: 0.01\n",
            "\n",
            "Trying LR: 0.005, Weight Decay: 0\n",
            "Epoch 1, Loss: 4.5273, Val Acc: 3.95%\n",
            "Epoch 2, Loss: 4.1709, Val Acc: 7.53%\n",
            "Epoch 3, Loss: 4.0037, Val Acc: 8.89%\n",
            "Epoch 4, Loss: 3.8710, Val Acc: 11.55%\n",
            "Epoch 5, Loss: 3.7333, Val Acc: 12.88%\n",
            "\n",
            "Trying LR: 0.005, Weight Decay: 1e-05\n",
            "Epoch 1, Loss: 4.5481, Val Acc: 4.27%\n",
            "Epoch 2, Loss: 4.1865, Val Acc: 7.23%\n",
            "Epoch 3, Loss: 4.0088, Val Acc: 9.33%\n",
            "Epoch 4, Loss: 3.8760, Val Acc: 10.82%\n",
            "Epoch 5, Loss: 3.7504, Val Acc: 12.61%\n",
            "\n",
            "Trying LR: 0.005, Weight Decay: 0.0001\n",
            "Epoch 1, Loss: 4.5565, Val Acc: 4.33%\n",
            "Epoch 2, Loss: 4.1953, Val Acc: 6.25%\n",
            "Epoch 3, Loss: 4.0289, Val Acc: 8.95%\n",
            "Epoch 4, Loss: 3.8844, Val Acc: 10.82%\n",
            "Epoch 5, Loss: 3.7528, Val Acc: 12.68%\n",
            "\n",
            "Trying LR: 0.01, Weight Decay: 0\n",
            "Epoch 1, Loss: 4.3436, Val Acc: 6.98%\n",
            "Epoch 2, Loss: 3.9815, Val Acc: 10.11%\n",
            "Epoch 3, Loss: 3.7584, Val Acc: 13.58%\n",
            "Epoch 4, Loss: 3.5796, Val Acc: 15.30%\n",
            "Epoch 5, Loss: 3.4500, Val Acc: 17.56%\n",
            "\n",
            "Trying LR: 0.01, Weight Decay: 1e-05\n",
            "Epoch 1, Loss: 4.3852, Val Acc: 5.88%\n",
            "Epoch 2, Loss: 4.0314, Val Acc: 9.55%\n",
            "Epoch 3, Loss: 3.8241, Val Acc: 10.96%\n",
            "Epoch 4, Loss: 3.6553, Val Acc: 14.08%\n",
            "Epoch 5, Loss: 3.5096, Val Acc: 16.81%\n",
            "\n",
            "Trying LR: 0.01, Weight Decay: 0.0001\n",
            "Epoch 1, Loss: 4.4157, Val Acc: 5.94%\n",
            "Epoch 2, Loss: 4.0597, Val Acc: 8.71%\n",
            "Epoch 3, Loss: 3.8900, Val Acc: 11.40%\n",
            "Epoch 4, Loss: 3.7092, Val Acc: 14.08%\n",
            "Epoch 5, Loss: 3.5399, Val Acc: 16.07%\n",
            "\n",
            "Trying LR: 0.02, Weight Decay: 0\n",
            "Epoch 1, Loss: 4.3246, Val Acc: 7.37%\n",
            "Epoch 2, Loss: 3.9823, Val Acc: 9.53%\n",
            "Epoch 3, Loss: 3.7473, Val Acc: 12.25%\n",
            "Epoch 4, Loss: 3.5706, Val Acc: 15.85%\n",
            "Epoch 5, Loss: 3.4396, Val Acc: 18.03%\n",
            "\n",
            "Trying LR: 0.02, Weight Decay: 1e-05\n",
            "Epoch 1, Loss: 4.3056, Val Acc: 6.66%\n",
            "Epoch 2, Loss: 3.9403, Val Acc: 10.65%\n",
            "Epoch 3, Loss: 3.7125, Val Acc: 12.91%\n",
            "Epoch 4, Loss: 3.5415, Val Acc: 16.08%\n",
            "Epoch 5, Loss: 3.4211, Val Acc: 17.18%\n",
            "\n",
            "Trying LR: 0.02, Weight Decay: 0.0001\n",
            "Epoch 1, Loss: 4.3053, Val Acc: 6.08%\n",
            "Epoch 2, Loss: 3.9935, Val Acc: 8.76%\n",
            "Epoch 3, Loss: 3.8176, Val Acc: 11.45%\n",
            "Epoch 4, Loss: 3.7093, Val Acc: 14.42%\n",
            "Epoch 5, Loss: 3.6401, Val Acc: 14.36%\n",
            "Best model parameters: {'lr': 0.02, 'weight_decay': 0, 'final_loss': 3.439582396316528, 'final_val_acc': 18.03, 'momentum': 0.9}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5f89f9aed6c3>\u001b[0m in \u001b[0;36m<cell line: 395>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-5f89f9aed6c3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;31m# Train the model for 10-20 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m       model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_early_stopping(\n\u001b[0m\u001b[1;32m    369\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimprovement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m       )\n",
            "\u001b[0;32m<ipython-input-3-5f89f9aed6c3>\u001b[0m in \u001b[0;36mtrain_model_with_early_stopping\u001b[0;34m(model, optimizer, criterion, scheduler, train_loader, val_loader, num_epochs, device, patience)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centralized baseline"
      ],
      "metadata": {
        "id": "KpPjPiOTFatY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "# Early Stopping Class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        #if self.verbose:\n",
        "        #    print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\")\n",
        "        #torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # Layer convolutivi\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)  # 3 input channels, 64 output channels\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)  # 64 input channels, 64 output channels\n",
        "\n",
        "        # Layer fully connected\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)  # Dimensione calcolata per input 32x32 con due conv e max-pooling\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)  # Classificatore lineare per CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer convolutivi con ReLU e max-pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling 2x2\n",
        "\n",
        "        # Flatten per i layer fully connected\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Layer fully connected con ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Classificatore lineare\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # Softmax per probabilità\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Centralized baseline training function\n",
        "def train_model_with_hyperparams(train_loader, val_loader, test_loader, best_hyperparams, num_epochs, device):\n",
        "    model = LeNet5().to(device)\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=best_hyperparams['lr'],\n",
        "        momentum=best_hyperparams['momentum'],\n",
        "        weight_decay=best_hyperparams['weight_decay']\n",
        "    )\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    early_stopping = EarlyStopping(patience=best_hyperparams.get('patience', 5), verbose=True)\n",
        "\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss_total, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss_total += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss_total / len(train_loader)\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss_total, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "                with autocast(device_type=device.type):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss_total += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss_total / len(val_loader)\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    # Test loop\n",
        "    model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_acc = 100. * test_correct / test_total\n",
        "    print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies, test_acc\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Use the best hyperparameters from random search\n",
        "    best_hyperparams = {\n",
        "        'lr': 0.01,\n",
        "        'weight_decay': 0.0001,\n",
        "        'momentum': 0.9,\n",
        "        'patience': 5\n",
        "    }\n",
        "\n",
        "    print(\"\\nUsing Best Hyperparameters:\", best_hyperparams)\n",
        "\n",
        "    # Train with the best hyperparameters\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies, test_acc = train_model_with_hyperparams(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        test_loader=test_loader,\n",
        "        best_hyperparams=best_hyperparams,\n",
        "        num_epochs=150,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Plot results\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "l6FFqW7ZFkWQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "save_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "plt.savefig(save_path + 'training_results.png')\n",
        "print(\"Training results saved to Google Drive as 'training_results.png'\")\n",
        "\n",
        "with open(save_path + 'training_summary.txt', 'w') as f:\n",
        "    f.write(f\"Final Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "    f.write(\"Training and Validation Results:\\n\")\n",
        "    f.write(f\"Train Losses: {train_losses}\\n\")\n",
        "    f.write(f\"Validation Losses: {val_losses}\\n\")\n",
        "    f.write(f\"Train Accuracies: {train_accuracies}\\n\")\n",
        "    f.write(f\"Validation Accuracies: {val_accuracies}\\n\")\n",
        "print(\"Training summary saved to Google Drive as 'training_summary.txt'\")\n",
        "\n",
        "torch.save(model.state_dict(), save_path + 'best_model.pth')\n",
        "print(\"Model saved to Google Drive as 'best_model.pth'\")\n"
      ],
      "metadata": {
        "id": "gPPYaRako9Zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}