{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheS1n233/Distributed-Learning-Project5/blob/experiments/LocalSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch\n"
      ],
      "metadata": {
        "id": "KlHheqAGVUVY",
        "outputId": "c399e4ef-0303-4844-c6ec-315d70cc7d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "u2T4ia3AsnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "from torch.amp import GradScaler, autocast\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "GPmLs0QzJQrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    raise RuntimeError(\"Google Drive not mounted correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yoNOiteP6yy",
        "outputId": "db47a3cd-1181-4421-9de7-03cfa71ba82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "bNvH-6hEsuxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
        "\n",
        "        # Layer fully connected\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer convolutivi con ReLU e max-pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # Flatten per i layer fully connected\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Layer fully connected con ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "da7YHCPoKnNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early stopping"
      ],
      "metadata": {
        "id": "t_8hLuI1syee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='/content/drive/MyDrive/Early2checkpoint.pt', verbose=False):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, optimizer=None):\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\")\n",
        "        checkpoint = {\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss_min': val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "HgFe_H-kNzFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to get train, test and val dataset"
      ],
      "metadata": {
        "id": "k8oCJ42etBK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size):\n",
        "    batch_size=batch_size\n",
        "    print(\"batch_size\", batch_size)\n",
        "    # Define the transform to only convert the images to tensors (without normalization yet)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Load the CIFAR-100 training dataset\n",
        "    train_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Initialize sums for calculating mean and std\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "\n",
        "    for images, _ in train_loader:\n",
        "        # Compute mean and std for each channel\n",
        "        mean += images.mean(dim=[0, 2, 3])\n",
        "        std += images.std(dim=[0, 2, 3])\n",
        "\n",
        "    mean /= len(train_loader)\n",
        "    std /= len(train_loader)\n",
        "\n",
        "    print(\"Mean: \", mean)\n",
        "    print(\"Std: \", std)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                            std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[mean[0].item(), mean[1].item(), mean[2].item()],\n",
        "                            std=[std[0].item(), std[1].item(), std[2].item()])\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-100 dataset\n",
        "    start_time = time.time()\n",
        "    train_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test\n",
        "    )\n",
        "    print(f\"Dataset loading time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Split training and validation sets\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Debugging: Check DataLoader outputs\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        print(f\"Batch {i}: inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "        if i == 10:  # Test first 10 batches\n",
        "            break\n",
        "    print(f\"Data loading for 10 batches completed.\")\n",
        "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "sMQZou82OL3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "10SkyrWdBkR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LocalSGD"
      ],
      "metadata": {
        "id": "nJaPDN4Qna1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_cifar100(dataset, num_workers):\n",
        "    indices = np.random.permutation(len(dataset))\n",
        "    splits = np.array_split(indices, num_workers)\n",
        "    return [torch.utils.data.Subset(dataset, split) for split in splits]\n",
        "\n",
        "\n",
        "def local_sgd(train_dataset, val_loader, test_loader, device, num_workers, local_steps, num_epochs, batch_size, hyperparams):\n",
        "    dataset_size = len(train_dataset)\n",
        "    datasets = split_cifar100(train_dataset, num_workers)\n",
        "    workers = [\n",
        "        torch.utils.data.DataLoader(\n",
        "            datasets[i],\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        for i in range(num_workers)\n",
        "    ]\n",
        "\n",
        "    total_iterations = (num_epochs * (dataset_size // batch_size)) // (num_workers * local_steps)\n",
        "    iterations_per_epoch = total_iterations // num_epochs\n",
        "\n",
        "    global_model = LeNet5().to(device)\n",
        "    local_models = [copy.deepcopy(global_model).to(device) for _ in range(num_workers)]\n",
        "    local_optimizers = [\n",
        "        optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=hyperparams['lr'],\n",
        "            weight_decay=hyperparams['weight_decay'],\n",
        "            momentum=hyperparams['momentum'],\n",
        "        )\n",
        "        for model in local_models\n",
        "    ]\n",
        "\n",
        "    schedulers = [CosineAnnealingLR(opt, T_max=num_epochs) for opt in local_optimizers]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    local_weights = [len(datasets[i].indices) / dataset_size for i in range(num_workers)]\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    save_path = f\"/content/drive/My Drive/Colab Notebooks/Traning_summary/K={num_workers}_J={local_steps}_Comparison_{timestamp}\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    metrics_files = {\n",
        "        'global_train_acc': os.path.join(save_path, f'localSGD_train_accuracy_{timestamp}_{str(batch_size)}.txt'),\n",
        "        'val_acc': os.path.join(save_path, f'localSGD_val_accuracy_{timestamp}_{str(batch_size)}.txt'),\n",
        "        'global_train_loss': os.path.join(save_path, f'localSGD_train_loss_{timestamp}_{str(batch_size)}.txt'),\n",
        "        'val_loss': os.path.join(save_path, f'localSGD_val_loss_{timestamp}_{str(batch_size)}.txt')\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(save_path, f'localSGD_experiment_config_{timestamp}_{str(batch_size)}.txt'), 'w') as f:\n",
        "        f.write(f\"Experiment Configuration:\\n\")\n",
        "        f.write(f\"Optimizer: localSGD\\n\")\n",
        "        f.write(f\"K = {num_workers}; J = {local_steps}\\n\")\n",
        "        f.write(f\"Hyperparameters: {str(hyperparams)}\\n\")\n",
        "        f.write(f\"Number of epochs: {num_epochs}\\n\")\n",
        "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
        "    val_losses, val_accuracies = [], []\n",
        "    train_losses, train_accuracies = [], []\n",
        "    #best_val_acc = 0.0\n",
        "    #best_model_state = None\n",
        "\n",
        "    worker_iters = [iter(workers[i]) for i in range(num_workers)]\n",
        "\n",
        "    for iteration in range(1, total_iterations + 1):\n",
        "        # Local training for H steps\n",
        "        for worker_id in range(num_workers):\n",
        "            local_models[worker_id].train()\n",
        "            for _ in range(local_steps):\n",
        "                try:\n",
        "                    inputs, labels = next(worker_iters[worker_id])\n",
        "                except StopIteration:\n",
        "                    worker_iters[worker_id] = iter(workers[worker_id])\n",
        "                    inputs, labels = next(worker_iters[worker_id])\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                local_optimizers[worker_id].zero_grad()\n",
        "                outputs = local_models[worker_id](inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                local_optimizers[worker_id].step()\n",
        "\n",
        "        # Model averaging after H steps\n",
        "        with torch.no_grad():\n",
        "            global_state_dict = global_model.state_dict()\n",
        "            for key in global_state_dict.keys():\n",
        "                global_state_dict[key] = torch.sum(\n",
        "                    torch.stack([\n",
        "                        local_weights[i] * local_models[i].state_dict()[key]\n",
        "                        for i in range(num_workers)\n",
        "                    ]),\n",
        "                    dim=0\n",
        "                )\n",
        "\n",
        "            global_model.load_state_dict(global_state_dict)\n",
        "            # Update local models with averaged weights\n",
        "            for local_model in local_models:\n",
        "                local_model.load_state_dict(global_state_dict)\n",
        "\n",
        "        if iteration % iterations_per_epoch == 0:\n",
        "            # Global metrics calculation\n",
        "            global_model.eval()\n",
        "            global_train_loss, global_correct, global_total = 0.0, 0, 0\n",
        "            with torch.no_grad():\n",
        "                # Train on the global model after local updates\n",
        "                for inputs, labels in workers[0]:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = global_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    global_train_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    global_correct += predicted.eq(labels).sum().item()\n",
        "                    global_total += labels.size(0)\n",
        "\n",
        "            global_train_loss /= len(workers[0])\n",
        "            global_train_acc = global_correct / global_total\n",
        "            train_losses.append(global_train_loss)\n",
        "            train_accuracies.append(global_train_acc)\n",
        "\n",
        "\n",
        "            # Validation\n",
        "            global_model.eval()\n",
        "            val_loss, correct, total = 0.0, 0, 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = global_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    correct += predicted.eq(labels).sum().item()\n",
        "                    total += labels.size(0)\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_acc = correct / total\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_acc)\n",
        "            try:\n",
        "                with open(metrics_files['global_train_acc'], 'a') as f:\n",
        "                    f.write(f\"{(iteration/total_iterations)*100:.2f}%,{global_train_acc * 100:.2f}%\\n\")\n",
        "                with open(metrics_files['val_acc'], 'a') as f:\n",
        "                    f.write(f\"{(iteration/total_iterations)*100:.2f}%,{val_acc * 100:.2f}%\\n\")\n",
        "                with open(metrics_files['global_train_loss'], 'a') as f:\n",
        "                    f.write(f\"{(iteration/total_iterations)*100:.2f}%,{global_train_loss:.4f}\\n\")\n",
        "                with open(metrics_files['val_loss'], 'a') as f:\n",
        "                    f.write(f\"{(iteration/total_iterations)*100:.2f}%,{val_loss:.4f}\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving metrics: {e}\")\n",
        "            #if val_acc > best_val_acc:\n",
        "                #best_val_acc = val_acc\n",
        "                #best_model_state = copy.deepcopy(global_model.state_dict())\n",
        "\n",
        "            print(f\"Iteration {iteration} / {total_iterations} -> {(iteration/total_iterations)*100:.2f}% | Train Loss: {global_train_loss:.4f}, Train Acc: {global_train_acc * 100:.2f}%  | Val Loss: {val_loss:.4f}, Val Acc: {val_acc * 100:.2f}%\")\n",
        "\n",
        "            # Step schedulers after each epoch\n",
        "            for scheduler in schedulers:\n",
        "                scheduler.step()\n",
        "\n",
        "    # Ripristina il miglior modello\n",
        "    #if best_model_state:\n",
        "        # global_model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Valutazione finale sul test set\n",
        "    global_model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = global_model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies, test_acc, total_iterations, iterations_per_epoch\n",
        "\n",
        "\n",
        "\n",
        "# Visualization function\n",
        "def plot_results(train_losses, val_losses, train_accuracies, val_accuracies, iterations_per_epoch, total_iterations):\n",
        "    # Dynamic calculation record points\n",
        "    recorded_iterations = len(train_losses)\n",
        "    iterations = range(iterations_per_epoch, iterations_per_epoch * recorded_iterations + 1, iterations_per_epoch)\n",
        "\n",
        "    # Ensure data length is consistent\n",
        "    assert len(train_losses) == len(iterations), f\"Train losses and iterations mismatch: {len(train_losses)} vs {len(iterations)}\"\n",
        "    assert len(val_losses) == len(iterations), f\"Validation losses and iterations mismatch: {len(val_losses)} vs {len(iterations)}\"\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(iterations, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(iterations, val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(iterations, train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(iterations, val_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Training and Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    num_epochs = 150\n",
        "    batch_size = 64\n",
        "    num_workers_list = [4,8,16,32,64]\n",
        "    local_steps_list = [1, 32, 64]\n",
        "    hyperparams = {\n",
        "        'lr': 0.01,\n",
        "        'weight_decay': 0.001,\n",
        "        'momentum': 0.9,\n",
        "    }\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_dataset(batch_size)\n",
        "    train_dataset = train_loader.dataset\n",
        "\n",
        "    for num_workers in num_workers_list:\n",
        "        for local_steps in local_steps_list:\n",
        "            print(f\"Running LocalSGD with {num_workers} workers and {local_steps} local steps\")\n",
        "            train_losses, val_losses, train_accuracies, val_accuracies, test_acc, total_iterations, iterations_per_epoch = local_sgd(\n",
        "                train_dataset=train_dataset,\n",
        "                val_loader=val_loader,\n",
        "                test_loader=test_loader,\n",
        "                device=device,\n",
        "                num_workers=num_workers,\n",
        "                local_steps=local_steps,\n",
        "                num_epochs=num_epochs,\n",
        "                batch_size=batch_size,\n",
        "                hyperparams=hyperparams,\n",
        "            )\n",
        "\n",
        "            plot_results(train_losses, val_losses, train_accuracies, val_accuracies, iterations_per_epoch, total_iterations)\n"
      ],
      "metadata": {
        "id": "SFiaXpZUnfDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "a0c4240d-2e8f-4fed-90e2-e322762e08b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size 64\n",
            "Files already downloaded and verified\n",
            "Mean:  tensor([0.5070, 0.4865, 0.4408])\n",
            "Std:  tensor([0.2664, 0.2555, 0.2750])\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset loading time: 1.90 seconds\n",
            "Batch 0: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 1: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 2: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 3: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 4: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 5: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 6: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 7: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 8: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 9: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Batch 10: inputs shape: torch.Size([64, 3, 32, 32]), labels shape: torch.Size([64])\n",
            "Data loading for 10 batches completed.\n",
            "Training dataset size: 40000\n",
            "Validation dataset size: 10000\n",
            "Test dataset size: 10000\n",
            "Running LocalSGD with 2 workers and 32 local steps\n",
            "Iteration 9 / 1464 -> 0.61% | Train Loss: 4.0877, Train Acc: 6.54%  | Val Loss: 4.0993, Val Acc: 6.35%\n",
            "Iteration 18 / 1464 -> 1.23% | Train Loss: 3.7693, Train Acc: 12.44%  | Val Loss: 3.7718, Val Acc: 12.04%\n",
            "Iteration 27 / 1464 -> 1.84% | Train Loss: 3.5574, Train Acc: 15.25%  | Val Loss: 3.5949, Val Acc: 14.24%\n",
            "Iteration 36 / 1464 -> 2.46% | Train Loss: 3.3249, Train Acc: 19.49%  | Val Loss: 3.3660, Val Acc: 18.22%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-735d79128dc2>\u001b[0m in \u001b[0;36m<cell line: 214>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlocal_steps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_steps_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running LocalSGD with {num_workers} workers and {local_steps} local steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             train_losses, val_losses, train_accuracies, val_accuracies, test_acc, total_iterations, iterations_per_epoch = local_sgd(\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-735d79128dc2>\u001b[0m in \u001b[0;36mlocal_sgd\u001b[0;34m(train_dataset, val_loader, test_loader, device, num_workers, local_steps, num_epochs, batch_size, hyperparams)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mworker_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "bNvH-6hEsuxY",
        "t_8hLuI1syee",
        "MhXxXjgks2K1",
        "IgKVfV0Ts7GD",
        "k8oCJ42etBK_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}